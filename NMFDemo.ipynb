{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates an example of running a single dataset through the lab's full analysis pipeline for NMF-based models.\n",
    "\n",
    "The main steps involved are:\n",
    "##### 1. Format Data \\[MATLAB\\]\n",
    "##### 2. Preprocessing \\[MATLAB\\]\n",
    "##### 3. Prepare data in Python \\[Python\\]\n",
    "##### 4. Train and evaluate NMF model \\[Python\\]\n",
    "##### 5. Save results \\[Python\\]\n",
    "##### 6. Interpret results \\[Python & MATLAB\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Format Data\n",
    "\n",
    "   The recorded data must be saved into a folder with the following structure:  \n",
    "   \n",
    "   The folder must have a subfolder named *Data* that contains a *.mat* file for each recording session.\n",
    "   Those files should have the following naming scheme: _**mouse-name**\\_**date**\\_**experiment-identifier**\\_LFP.mat_ (example: *Mouse798_021519_CUS_LFP.mat*).\n",
    "   Each file in data should contain variables containing vectors of recorded data corresponding to each of the channels recorded in that session.  \n",
    "   \n",
    "   The same folder containing data must have another subfolder named *CHANS* that has *.mat* files corresponding to each of the files in *Data*.\n",
    "   Each file in *CHANS* should have the follwing naming scheme:  _**mouse-name**\\_**date**\\_**experiment-identifier**\\_CHANS.mat_ (example: *Mouse798_021519_CUS_CHANS.mat*).\n",
    "   Each of these files should contain 2 variables, **CHANNAMES** and **CHANACTIVE**.\n",
    "   **CHANNAMES** should be an array of strings giving the names of each of the channels in the corresponding LFP file.\n",
    "   **CHANACTIVE** should be a vector of 1s or 0s.\n",
    "   If **CHANACTIVE**(k) = 0, it indicates that the channel given by **CHANNAMES**(k) should not be included in preprocessing; conversely, **CHANACTIVE**(k) = 1 means that **CHANNAMES**(k) should be included in preprocessing.\n",
    "   For more info on converting recorded data from the *.ns2* format to the format described here, ask Steve Mague. \n",
    "   \n",
    "   You must also create an excel spreadsheet with two columns containing channel information.\n",
    "   The first column should be a master list of all the channel names that will appear in the dataset (e.g. **NAc_Shell_02**).\n",
    "   The second column should give the abbreviated name of the area that each channel corresponds to; for instance you might list **NAc_Shell** as the area for the channel **NAc_Shell_02**.\n",
    "   You can use the area labels to combine data from different hemispheres or from multiple nearby regions.\n",
    "   For example, the channels **NAc_Shell_02** and **NAc_Core_01** might both have **NAc** listed as their corresponding area if you wish to combine data from Nucleus Accumbens core and shell.\n",
    "   \n",
    "   If the optional *useIntervals* parameter is set to **true**, then the project folder must also contain a subfolder named *INT_TIME*.\n",
    "   Setting *useIntervals* to **true** will allow you to select only specific intervals of the recording to preprocess and save.\n",
    "   That folder should contain *.mat* files corresponding to each file in the *Data* folder with the following naming scheme: _**mouse-name**\\_**date**\\_**experiment-identifier**\\_TIME.mat_ (example: *Mouse798_021519_CUS_TIME.mat*).\n",
    "   Each of those files will contain a single vector variable named **INT_TIME** that should have *2N* entries, where *N* is the total number of intervals you wish to use.\n",
    "   The odd entries (1,3,5,...) contain the starting time (in seconds) of each interval, and the even entries (2,4,6...) contain the duration of each interval in seconds.\n",
    "\n",
    "   To format recorded data into windows, run *formatWindows* in MATLAB. *formatWindows* takes one parameter, which names the file that you will save the formatted data to.                                                                                 \n",
    "\n",
    "Example:                                                                                                                       \n",
    "\n",
    "```matlab\n",
    "formatWindows('myTestFile.mat')\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2a: Preprocessing\n",
    "\n",
    " To preprocess formatted data, run *preprocessData* in MATLAB. *preprocessData* has one required input parameter, which should be the same filename given to *formatWindows*.\n",
    "A second optional parameter can be used to change preprocessing options.\n",
    "\n",
    "run in MATLAB: ```preprocessData(myTestFile.mat, dataOpts)```\n",
    "\n",
    " \n",
    " Replace 'myTestFile.mat' with the name/location of the file containing your data. *dataOpts* is a structure that you can use to optionally change some of the settings for preprocessing; you can use it to change the following settings:\n",
    "* subSampFact: subsampling factor\n",
    "* normWindows: String indicating of how to normalize data. If 'window', each window is normalized seperately. If 'whole', dataset is normalized as a whole, and individual windows are still set to have zero mean. Set to 'mouse' to normalize channels seperately for each mouse, or 'day' to normalize within day for each channel for each mouse. Can be set to 'none' if no normalization is desired. Default is 'day'.\n",
    "* transform: whether or not to take and save the Fourier transform of the data\n",
    "\n",
    "Additionally, if you plan on using the data you are preprocessing to 'backproject' into another model that was trained using other data, you will want to preprocess this data with some of the preprocessing parameters used on the training set. To do that, load the *dataOpts* variable from the file where your preprocessed training set is saved and use that as the *dataOpts* parameter for *preprocessData*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2b. Calculate frequency-based features\n",
    "**In MATLAB:**\n",
    "\n",
    "Run the saveFeatures function to generate features such as power, coherence, or Granger causality.\n",
    "\n",
    "```matlab\n",
    "opts.featureList = {'power', 'coherence', 'granger'}; \n",
    "opts.mvgcFolder = '~/lpne-data-analysis/mvgc/'\n",
    " \n",
    "saveFeatures(‘myTestFile.mat’, opts);\n",
    "```\n",
    "Again, replace 'myTestFile.mat' with the name/location of the file containing your data. opts is a structure that you can use to optionally change some of the settings for feature generate; you can use it to change the following settings:\n",
    "* featureList: cell array of features to calculate. Options are 'power', 'coherence', and/or 'granger'\n",
    "* mvgcFolder: (Only needed if you want to calculate granger features) String giving path to MVGC toolbox. There is a copy of this toolbox inside the lpne-data-analysis repository, so you should be able to use that location\n",
    "* parCores: integer indicating number of cores to use for  parallel computing. If 0 (default), all tasks executed in serial.\n",
    "* windowOpts:  a binary vector with length=number of windows, determining which windows to analyze for features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Prepare Data in Python\n",
    "\n",
    "**NOTE:** To run the Python components of this notebook, you will need a matlab (.mat) file containing variables 'power', 'coherence', and/or 'granger', and a JSON file containing 'labels'.\n",
    "You will also need the lpne-data-analysis git repository as well as the NMF_tf repository.\n",
    "\n",
    "Demo data to run this can be found at LabCommon/AnalysisDemoData.\n",
    "\n",
    "### Edit paths to pipeline, NMF_tf, and datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "my_home = str(Path.home())\n",
    "\n",
    "# Edit pipeline path here\n",
    "pipepath = my_home + '/lpne-data-analysis'\n",
    "# Edit path to NMF_tf folder here\n",
    "nmfpath = my_home + '/NMF_tf/'\n",
    "# Enter path to '.mat' data file here\n",
    "datapath = '/work/nmg14/TST/TeST.mat'\n",
    "\n",
    "# set name for nmf models to be saved with\n",
    "name = 'testModel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(pipepath)\n",
    "sys.path.append(my_home)\n",
    "sys.path.append(nmfpath)\n",
    "\n",
    "import data_tools\n",
    "import validation_tools\n",
    "import numpy as np\n",
    "import norm_base, norm_supervised\n",
    "import pickle\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and extract the data\n",
    "*load_features* should be a list of strings describing the features you want to extract from the file given by *datapath*. \n",
    "Typically the options you would choose are 'power', 'coherence', 'granger', and/or 'instant' (instantaneous causality). \n",
    "The features are returned in the order that you list them. \n",
    "\n",
    "The last return value is a dictionary of labels that includes the following keys:            \n",
    "* 'windows': Dictionary containing information associated with each individual time-window. Some options for keys included in this dictionary inclue 'task' (i.e. task being done by mouse) and 'mouse' (i.e. name of mouse).\n",
    "* 'powerFeatures': list of string labels describing the features represented in power.\n",
    "* 'cohFeatures': list of string labels describing the features represented in coherence\n",
    "* 'gcFeatures': list of string labels describing the features represented in granger\n",
    "* 'instFeatures': list of string labels describing the features represented in instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_features = ['power', 'granger']\n",
    "\n",
    "power, granger, labels = \\\n",
    "data_tools.load_data(datapath, feature_list=load_features, f_bounds=(1,55))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate one-hot vector for output\n",
    "The *target* should be the key in labels\\['windows'\\] that you would like to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'task'\n",
    "y = data_tools.get_labels(labels, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) group mice together to balance some desired variable\n",
    "You may want your training/test sets to maintain balanced numbers of some variable (e.g. genotype). To do this the second input parameter should be some key in labels\\['windows'\\]. If you just want to group all of the windows for individal mice together, run the commented out line below instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = validation_tools.get_balanced_groupings(labels, 'genotype')\n",
    "\n",
    "#groups = data_tools.get_labels(labels, 'mouse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train and evaluate NMF model\n",
    "\n",
    "### choose model and training options\n",
    "To use cross-validation to choose to between multiple options for any parameter, set that parameter to a list of all the options you would like to consider. Comment out the line associated with any option to use the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opts = {'train func':norm_base.train_model,\n",
    "              'eval func':norm_base.evaluate_model}\n",
    "\n",
    "params=dict()\n",
    "params['dir name'] = name + 'Dir'   \n",
    "# directory to which you would like to save model checkpoints\n",
    "\n",
    "params['name'] = name   \n",
    "# name associated with your model\n",
    "\n",
    "params['n components'] = 5   \n",
    "# number of factors in model\n",
    "\n",
    "params['learning rate'] = 1e-4  \n",
    "# learning rate\n",
    "\n",
    "params['superstrength'] = 3   \n",
    "# strength of supervision\n",
    "\n",
    "params['n iter'] = 150000   \n",
    "# number of training iterations\n",
    "\n",
    "params['NMF variant'] = norm_supervised.sNMF   \n",
    "# model class that you would like to use within the NMF_tf repository\n",
    "\n",
    "params['feature_weights'] = [[1,1]]   \n",
    "# relative weighting of features included in 'feature_list'\n",
    "# Must be a list of lists\n",
    "\n",
    "gen = data_tools.get_labels(labels, 'genotype')\n",
    "params['samp weights'] =  np.ones_like(gen) + 2*np.asarray(gen) \n",
    "# use 'samp weights' if you want to weight windows differently when training the model. This\n",
    "# example weights windows from a specific genotyp 3x.\n",
    "\n",
    "params['repeats'] = 5\n",
    "# number of times to repeat each combination of parameters\n",
    "# the best training session will be take from the repeats\n",
    "\n",
    "feature_list = [power, granger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Option A:** Use cross-validation to learn a model\n",
    "Cross-validation is useful when you want to test multiple values for one or more parameters. We use grid search cross-validation, which will train a model for each combination of parameter values you want to test on multiple different subsets of the data. The run_cv method will do this and then train a final model using the combination of parameters that performs the best over all of the data subsets (more specifically on the data that was held out from each subset).\n",
    "\n",
    "Change *folds* to the number of cross-validation folds you would like to use. \n",
    "\n",
    "Set *metric* to 'accuracy', 'auc' or 'precision' if you want to use the area under the ROC curve or precision-recall curve, respectively, to evaluate performance. Generally 'auc' or 'precision' are preferred over 'accuracy', but 'accuracy' is arguably more interpretable in multi-class situations. 'auc' is most appropriate when you have approximately the same number of observations for each class in *y* (e.g. half of the observations are class 'A' and half are class 'B') 'precision' is more appropriate when your classes are not balanced (when using 'precision' the class with fewer observations should be the positive class). A good rule of thumb is to use 'precision' when the ratio between classes is greater than 5:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cv_output\n",
    "# this line saves the training output without printing it\n",
    "# To print it later run 'cv_output.show()'\n",
    "\n",
    "cv_results = validation_tools.run_cv(feature_list, y, groups, folds=3, metric='auc', \n",
    "                                parameters=params, modelOpts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Option B:** Use nested cross-validation to estimate the performance of a *class* of models\n",
    "Nested cross-validation is useful when you want an unbiased estimate of how well a certain class of models performs on your data. In nested cross-validation you perform cross-validation on multiple subset of your data and get a seperate final model for each subset. The performance of each model is then evaluated on the portion of the data not included in the subset it was trained on, giving a set of unbiased performance values for each subset of data. You can use these performance values to estimate the mean and variance of the type of model you are using on your dataset. **Note:** This is different than traditional cross-validation because you do not finish with a single final model for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture ncv_output\n",
    "\n",
    "ncv_results = validation_tools.run_nested_cv(feature_list, y, groups, folds=5, metric='auc', \n",
    "                                parameters=params, modelOpts=model_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backproject  holdout dataset into model\n",
    "Repeat data loading and preparation for holdout set as you did for the training set. See comments below for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit path to holdout data\n",
    "holdout_path = '/home/data_store1/TST/TeST.mat'\n",
    "\n",
    "# set this to have the same number of outputs as for the training set\n",
    "power2, granger2, labels2 = \\\n",
    "data_tools.load_data(holdout_path, feature_list=load_features)\n",
    "y2 = data_tools.get_labels(labels2, target)\n",
    "\n",
    "feat_weights = cv_results['parameters']['feature_weights']\n",
    "\n",
    "# Choose the same set of features as training to project into the model\n",
    "feature_list2 = [power2, granger2]\n",
    "X2 = data_tools.get_X(feat_weights, feature_list2)\n",
    "holdout_perf, holdout_data = norm_base.evaluate_model(cv_results['model'], data=(X2, y2), \n",
    "                                                      metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print performance statistics\n",
    "Prints the performance metric (e.g. AUC) on each of the test set splits, along with mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = ncv_results['performance']\n",
    "print('Nested Cross-validation performance: \\n', perf)\n",
    "print('mean: %.2f -  SD: %.2f' % (np.mean(perf), np.std(perf)))\n",
    "\n",
    "print('\\n Holdout Performance:\\n', holdout_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = cv_results['model'][0]\n",
    "factors = nmf_model.components_\n",
    "\n",
    "savedata = cv_results.copy()\n",
    "savedata['factors'] = factors\n",
    "savedata['classifier'] = cv_results['model'][1]\n",
    "savedata.pop('model',None)\n",
    "\n",
    "pickle.dump(savedata, open('cvResults.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot features included in factors\n",
    "\n",
    "Regions in the feature set are listed above. To plot power, set *plot_feature* to 'p *region*', where *region* is one of the regions listed above. To plot Granger causality set *plot_feature* to '*region1*->*region2*'. To plot coherence set *plot_feature* to '*region1*-*region2*' (for coherence there is only one correct ordering for a given pair of regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature = 'IL_Cx-Acb_Sh'\n",
    "factor_no = 0 # supervised factors come first\n",
    "# assumes that feature_list used to train model contains \n",
    "# power and granger features, in that order\n",
    "feature_labels = np.hstack((labels['powerFeatures'], labels['gcFeatures']))\n",
    "\n",
    "validation_tools.plot_factors(factors, plot_feature, factor_no, feature_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot factor scores over time (for holdout set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_no = 2\n",
    "\n",
    "plt.plot(holdout_data['scores'][:,factor_no])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-import modules if they've been edited\n",
    "\n",
    "import importlib\n",
    "importlib.reload(norm_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
